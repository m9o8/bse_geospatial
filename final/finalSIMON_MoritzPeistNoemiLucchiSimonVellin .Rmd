---
title: "Geospatial Data Science - Final project"
author:
- Moritz Peist
- Noemi Lucchi
- Simon Vellin
subtitle: Analysis of US Road Accidents and Construction Sites (TBC)
output:
  html_document:
    toc: true
    df_print: paged
  html_notebook:
    df_print: paged
    toc: true
---

<hr>

```{css, echo=FALSE}
h1.title {
  text-align: center;
}

h4.author, h4.date {
  text-align: center;
}

.author {
  text-align: center;
}

.date {
  text-align: center;
}

/* Add styling for subtitle */
h3.subtitle {
  text-align: center;
  font-style: italic;
  margin-top: -10px;
  color: #606060;
}
```

```{r setup, include=FALSE}
# Disable warning messages
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

<div style="text-align: center;">
  <img src="../Barcelona_School_of_Economics_logo.svg" alt="BSE logo">
</div>

<hr>

# Purpose of Study

This study investigates the causal effect of road construction and closures on accident rates in the United States by employing a propensity score matching framework to compute a difference-in-differences regression. Using two distinct datasets — US Accidents (2016–2023) and US Road Construction and Closures (2016–2021) — this paper aims to rigorously assess how construction-related disruptions influence the frequency and severity of traffic accidents.

Although a substantial body of literature has examined the latter, the specific integration of causal inference techniques remains less prevalent. As such, our approach provides a robust methodology by matching treated and control segments based on relevant covariates, which isolates the studied effect by comparing changes in accident rates over time between matched groups.

After quickly reviewing existing literature, we will justify the use of propensity score matching and difference-in-differences before implementing our code in Part 3. Finally, the last section will display our results while mentioning the limits of our study, as well as the potential improvements for subsequent analysis.

# Part 1 - Literature Review

In order to familiarize ourselves with the topic, we have been through two existing papers relating to accidents in the US, serving as a baseline understanding to start our study. Although we would have preferred introducing one of Mohamed Abdel-Aty's studies, widely recognized for his contributions to transportation safety, he employs advanced statistical modeling techniques which appears less related to Geospatial & Economic litterature compared to the ones that we decided to present below.

## 2.1 "Effects of truck traffic on crash injury severity on rural highways in Wyoming using Bayesian binary logit models" by Ahmed et al. (2018)

This paper explores the impact of truck traffic and roadway geometry on crash frequency within highway work zones, using a case study from Wyoming spanning 2012–2016.

Using crash data and statistical modeling, the authors assess how construction-related factors, like lane closures and heavy vehicle presence, elevate accident risks. Their paper reveals that increased truck volumes and sharper geometric features significantly amplify crash rates, with work zones acting as hotspots for such incidents. While the paper employs logistic regression rather than causal inference techniques, it underscores the real-world relevance of construction disruptions on traffic safety.

This work provides a practical foundation for our study, highlighting the need to isolate causal effects of construction using advanced methods. By focusing on observable crash patterns, Ahmed et al. set the stage for deeper methodological exploration in our difference-in-differences framework.

URL - https://www.sciencedirect.com/science/article/pii/S0001457518301507

## 2.2 "Comparison of characteristics between fatal and injury accidents in the highway construction zones" by Li and Bai (2008)

This paper investigates the characteristics of accidents in highway construction zones from a statistical perspective, comparing fatal and injury crashes using data from Utah between 1992 and 2004.

Using traffic volume, construction duration, and time of day, their results show that construction zones markedly increase accident likelihood, with fatal crashes tied to higher speeds and nighttime conditions. Although the study relies on descriptive statistics and regression rather than causal frameworks, it offers critical insights into how construction alters road safety dynamics.

It supports our research by establishing a clear link between construction activities and accident rates, justifying our use of propensity score matching and difference-in-differences. Ideally, our approach aims to address the methodological gaps they leave unexplored.

URL - https://www.sciencedirect.com/science/article/pii/S0925753507001014

# Part 2 - Methodology

In this section, we start by providing summary statistics of the datasets we have found for our study, while detailing the theoretical justifications underlying the two main tools used to compute our results.

## 2.1 Dataset Overview

For both datasets, the data was collected using multiple APIs such as the US and state departments of transportation, law enforcement agencies, traffic cameras, and traffic sensors within the road networks.

### a. US Accidents (2016 - 2023)

This is a countrywide car accident dataset that covers 49 states of the USA. The dataset currently contains approximately 7.7 million accident records.

```{Descriptive Statistics of Data 1}

```

### b. US Road Construction and Closures (2016 - 2021)

This is a countrywide dataset of road construction and closure events, which covers 49 states of the US, ranging from fixing pavements to substantial projects that could take months to finish. Currently, there are about 6.2 million construction and closure records in this dataset.

```{Descriptive Statistics of Data 2}

```

## 2.2 Propensity Score Matching

Propensity Score Matching (PSM) is a statistical technique designed to estimate causal effects by balancing treatment and control groups based on observed covariates, tackling selection bias inherent to observational data like ours.

Here, “treatment” denotes road segments with construction or closures, while “control” covers unaffected segments. PSM hinges on the Conditional Independence Assumption, which stipulates that given a set of covariates $X$ (e.g., traffic volume, road type, weather), treatment assignment is independent of the outcome—accident rates. This is expressed as:

$$Y(0), Y(1) \perp T \mid X,$$

where $Y(1)$ and $Y(0)$ represent potential outcomes under treatment and control, and $T$ is the treatment indicator. PSM estimates the propensity score, the probability of treatment given covariates, as:

$$PSM(X) = P(T = 1 \mid X),$$

typically via logistic regression. We then match treated and control units with similar $PSM(X)$ values, ensuring comparability. The average treatment effect on the treated (ATT) is:

$$ATT = E[Y(1) - Y(0) \mid T = 1] = E[Y(1) \mid T = 1] - E[Y(0) \mid T = 1],$$

where $E[Y(0) \mid T = 1]$ is inferred from matched controls. For our study, PSM balances segments on pre-construction traits, 'mimicking' randomization to isolate construction’s effect. This is vital since construction isn’t randomly assigned (i.e. busier roads might be more prone to work). We’ll use nearest-neighbor matching and assess balance with standardized differences. PSM excels at handling multiple covariates, fitting our US Road Construction and Closures dataset, but requires strong assumption (CIA) and sufficient overlap in $PSM(X)$ (common support).

## 2.3 Difference-in-Differences

Difference-in-Differences (DiD) is a quasi-experimental approach that estimates causal effects by comparing outcome changes over time between treated (roads with construction) and control (roads without) groups. It requires the parallel trends assumption: without treatment, accident rate differences between groups would stay constant over time. The model is:

$$Y_{it} = \beta_0 + \beta_1 T_i + \beta_2 Post_t + \beta_3 (T_i \times Post_t) + \epsilon_{it},$$

where $Y_{it}$ is the accident rate for segment $i$ at time $t$, $T_i$ is the treatment dummy (1 for construction, 0 otherwise), $Post_t$ is the time dummy (1 post-construction, 0 pre), and $\beta_3$ is the DiD estimator. This is calculated as:

$$\beta_3 = (E[Y_{T=1,Post}] - E[Y_{T=1,Pre}]) - (E[Y_{T=0,Post}] - E[Y_{T=0,Pre}]),$$

capturing the treatment effect by differencing pre-post changes across groups.

In our context, DiD compares accident rates before and after construction starts, between treated and control segments, controlling for time-invariant confounders and shared trends. We’ll verify parallel trends by plotting pre-treatment accident rates and testing statistically. Challenges include potential trend violations or spillovers (i.e. traffic rerouting to control roads), but DiD’s strength lies in exploiting time variation, making it ideal for tracing construction’s impact on accident trajectories.

# Part 3 - Implementation

## 3.0 Load Packages

Start by loading the packages required to run this section.

```{r Packages}
library(data.table)   # For faster data manipulation
library(tidyverse)    # For data manipulation and visualization
library(sf)           # For spatial data handling
library(leaflet)      # For interactive maps
library(leaflet.extras) # For additional leaflet features
library(mapview)      # For easier map visualization
library(tmap)         # For thematic maps
library(tigris)       # For US road networks
library(future)       # For parallel processing
library(future.apply) # For parallel processing with apply functions
library(sf)           # For spatial data handling
library(RPostgres)    # For PostgreSQL connection
library(DBI)          # For database interface

# Create directories if they don't exist
if (!dir.exists("./data/tigris")) {
  dir.create("./data/tigris", recursive = TRUE)
}

# Set custom cache directory (optional)
options(tigris_cache_dir = "./data/tigris")
# Configure tigris to use caching
options(tigris_use_cache = TRUE)
```

## 3.1 Descriptive Maps

### a. Static Maps

```{r Static Maps}
# Static map for Accidents with year coloring
# First, store your plot in a variable
ca_plot <- ggplot() +
  geom_sf(data = ca_roads, color = "gray80", size = 0.1) +
  geom_sf(data = df.acc.sf %>% filter(State == "CA"), 
          aes(color = factor(year)), alpha = 0.7, size = 0.5) +
  scale_color_viridis_d(name = "Year") +  # Use viridis color palette for discrete values
  theme_minimal() +
  labs(title = "US Road Accidents by Year (2016-2021)") +
  theme(legend.position = "bottom")
print(ca_plot)
# Then save it using ggsave
ggsave(filename = "imgs/california_accidents.png", 
       plot = ca_plot,
       width = 10, # width in inches
       height = 8, # height in inches
       dpi = 300)  # resolution

# Construction sites map with year coloring
# First, store our plot in a variable
ca_const_plot <- ggplot() +
  geom_sf(data = ca_roads, color = "gray80", size = 0.1) +
  geom_sf(data = df.const.sf %>% filter(State == "CA"), 
          aes(color = factor(year)), alpha = 0.7, size = 0.5) +
  scale_color_viridis_d(name = "Year") +  # Use viridis color palette for discrete values
  theme_minimal() +
  labs(title = "US Construction Sites by Year (2016-2021)") +
  theme(legend.position = "bottom")
print(ca_const_plot)
# Then save it using ggsave
ggsave(filename = "imgs/california_construction.png", 
       plot = ca_const_plot,
       width = 10, # width in inches
       height = 8, # height in inches
       dpi = 300)  # resolution
```


### b. Heatmaps

#### (i) Static

```{r Heatmap static}
# Create heatmap of accidents using ggplot2
# Modified accident heatmap with transparency for low density areas
accident_heatmap <- ggplot() +
  # Add California roads as base layer
  geom_sf(data = ca_roads, color = "gray80", size = 0.1) +
  # Create density heatmap with transparency threshold
  stat_density_2d(
    data = df.acc %>% filter(!is.na(Start_Lat) & !is.na(Start_Lng)),
    aes(x = Start_Lng, y = Start_Lat, fill = after_stat(density), alpha = after_stat(density)),
    geom = "tile", 
    contour = FALSE,
    h = 0.1,
    n = 200
  ) +
  # Set alpha scaling with a minimum threshold
  scale_alpha_continuous(range = c(0, 0.9), guide = "none") +
  # Use color scheme similar to leaflet's default heatmap
  scale_fill_gradientn(
    colors = c("#0000FF", "#00FFFF", "#00FF00", "#FFFF00", "#FF0000"),
    name = "Accident\nDensity"
  ) +
  coord_sf(
    xlim = c(-124.5, -114.5),
    ylim = c(32.5, 42.5)
  ) +
  theme_minimal() +
  labs(
    title = "Accident Density Heatmap in California (2016-2021)",
    x = NULL,
    y = NULL
  ) +
  theme(
    legend.position = "right",
    plot.title = element_text(face = "bold")
  )
# Display the plot
print(accident_heatmap)

ggsave(filename = "imgs/accident_heatmap.png", 
       plot = accident_heatmap,
       width = 10, # width in inches
       height = 8, # height in inches
       dpi = 300)  # resolution

```

```{r Construction Heatmap static}
# Create heatmap of construction sites using ggplot2
construction_heatmap <- ggplot() +
  # Add California roads as base layer
  geom_sf(data = ca_roads, color = "gray80", size = 0.1) +
  # Create density heatmap
  stat_density_2d(
    data = df.const %>% filter(!is.na(Start_Lat) & !is.na(Start_Lng)),
    aes(x = Start_Lng, y = Start_Lat, fill = after_stat(density)),
    geom = "tile", 
    contour = FALSE,
    alpha = 0.7,
    h = 0.1,  # Bandwidth
    n = 200   # Resolution
  ) +
  # Set alpha scaling with a minimum threshold
  scale_alpha_continuous(range = c(0, 0.9), guide = "none") +
  # Use color scheme matching your leaflet construction map
  scale_fill_gradientn(
    colors = c("yellow", "orange", "red"),
    name = "Construction\nDensity"
  ) +
  # Set appropriate boundaries for California
  coord_sf(
    xlim = c(-124.5, -114.5),
    ylim = c(32.5, 42.5)
  ) +
  theme_minimal() +
  labs(
    title = "Construction Density Heatmap in California (2016-2021)",
    x = NULL,
    y = NULL
  ) +
  theme(
    legend.position = "right",
    plot.title = element_text(face = "bold")
  )
# Display the plot
print(construction_heatmap)
```


#### (ii) Interactive


```{r Interactive Maps I}
# For interactive maps (often better for large datasets)
# Accidents map
accident_map <- leaflet() %>%
  addTiles() %>%
  addHeatmap(data = df.acc.sf, 
             intensity = ~1,
             radius = 8, 
             blur = 10) %>%
  setView(lng = -119.4179, lat = 36.7783, zoom = 6) %>% # Center to CA
  setMaxBounds(lng1 = -124.6, lat1 = 42.0,    # Northwest corner of CA
               lng2 = -114.1, lat2 = 32.5)    # Southeast corner of CA

# Display maps
accident_map
```


```{r Interactive Maps II}
# Construction sites map with California focus and bounds constraints
construction_map <- leaflet() %>%
  addTiles() %>%
  addHeatmap(data = df.const.sf, 
             intensity = ~1,
             radius = 8, 
             blur = 10,
             gradient = c("yellow", "orange", "red")) %>%
  setView(lng = -119.4179, lat = 36.7783, zoom = 6) %>%  # Center on California
  setMaxBounds(lng1 = -124.6, lat1 = 42.0,    # Northwest corner of CA
               lng2 = -114.1, lat2 = 32.5)    # Southeast corner of CA

# Display the map
construction_map
```

Given the large amount of data, further visual analysis is specific to California and 2021. 
We start with some basic visualizations of our sampled data, firstly focusing on accidents.

```{r}
# Plot the accidents 
accidents <- ggplot() +
  geom_sf(data = ca_roads, color = "gray50", size = 1.5, linetype = "solid") +
  geom_sf(data = df.acc.sf, size = 0.2) +
  scale_color_viridis_c(
    name = "AADT",
    option = "plasma",
    labels = scales::comma) +
  theme_bw() +
  labs(title = "Accidents") 
print(accidents)
```


```{r}
# Plot accidents by severity 
accidents_severity <- ggplot() +
  geom_sf(data = ca_roads, color = "gray50", size = 1.5, linetype = "solid") +
  geom_sf(data = df.acc.sf, aes(color = Severity), size = 0.2) +
  scale_color_viridis_c(
    name = "Severity",
    option = "plasma",
    labels = scales::comma) +
  theme_bw() +
  labs(title = "Accidents by Severity") 
print(accidents_severity)
```

We can observe that most of the accidents are classified as level 2 severity. This suggests that the majority are not highly severe. Given this context, it is reasonable to infer that these accidents may be caused by distractions or disruptions, potentially linked to the presence of construction sites.


Now, we shift our focus to construction sites, still concentrating solely on California. Due to the extremely high number of construction sites, many of which last only a few minutes or hours, we decided to exclude those with durations of less than one day. This reduction in the number of construction sites not only improves the clarity of the visualization but also prevents any potential bias in the subsequent analysis. Considering that in afterwards we will implement a 300-meter buffer, including too many short-duration sites would essentially cover all areas with construction buffers, skewing the results.

```{r}
# Remove constructions that last less than one day
df.const.sf_filtered <- subset(df.const.sf, duration >= 1)
```


```{r}
# Plot the construction sites by severity 
constructions_severity <- ggplot() +
  geom_sf(data = ca_roads, color = "gray50", size = 1.5, linetype = "solid") +
  geom_sf(data = df.const.sf_filtered, aes(color = Severity), size = 0.2) +
  scale_color_viridis_c(
    name = "AADT",
    option = "plasma",
    labels = scales::comma) +
  theme_bw() +
  labs(title = "Constructions Sites by Severity") 
print(constructions_severity)
```

In the context of construction sites, severity reflects the expected impact on traffic, with a scale ranging from 1 to 4, where 1 represents the least impact. We can observe that the majority of construction sites are expected to have a minimal impact on traffic, with a severity score of 1. However, there are a few sites with a higher severity score, particularly around Los Angeles and Sacramento. This suggests that traffic volume may already be taken into account when calculating the severity of these sites.

```{r}
constructions_duration <- ggplot() +
  geom_sf(data = ca_roads, color = "gray50", size = 1.5, linetype = "solid") +
  geom_sf(data = df.const.sf_filtered, aes(color = duration), size = 0.2) +
  scale_color_viridis_c(
    name = "Duration",
    option = "plasma",
    labels = scales::comma) +
  theme_bw() +
  labs(title = "Constructions Sites by Duration") 
print(constructions_duration)
```

Now we combine our data about construction sites and accidents with data about traffic volume, the latter is referred to 2023, and was retrieved from the [U.S. Government's Open Data Website](https://data.gov). Traffic volume data was used to normalize the accident data, as we believed that comparing raw accident figures without accounting for the number of vehicles on the street could lead to biased results. Although the approach of combining different years for different sources of data is not methodologically robust, it helped in serving our purpose with the constraint of availability of data. Additionally, we assumed that the distribution of the kind of data we are analyzing is persistent, and so values are not likely to significantly change in a 2-year period.
In the aforementioned website, we found data about Annual Average Daily Traffic (AADT), which is the total volume for the year divided by 365 days. The traffic count year runs from October 1st through September 30th. We had information about both back and ahead AADT, as well as back peak hour traffic volume and ahead peak hour traffic volume, referred to the post miles (instead of roads). We average the back and ahead values for every pair of indicators and perform our analysis with both to verify which one could have been more insightful. As expected, the average AADT shows more variability, making it more effective for our normalization purpose.


```{r}
# Define average AADT and average peak traffic volume and substitute original columns 
traffic_data_aggregated <- df.traf.vol %>%
  mutate(across(c(BACK_AADT, AHEAD_AADT, BACK_PEAK_, AHEAD_PEAK), 
                ~as.numeric(as.character(.)))) %>%
  # Average over back and ahead traffic - both in AADT and peak traffic 
  mutate(
    aadt = rowMeans(cbind(AHEAD_AADT, BACK_AADT), na.rm = TRUE),
    avg_peak_traffic = rowMeans(cbind(BACK_PEAK_, AHEAD_PEAK), na.rm = TRUE)
  ) %>%
  # Remove initial columns 
  select(-c(AHEAD_AADT, BACK_AADT, AHEAD_PEAK, BACK_PEAK_, AHEAD_PE_1, BACK_PEA_1))
  
```


```{r}
# Plot average AADT with roads 
traffic_roads <- ggplot() +
  geom_sf(data = ca_roads, color = "gray50", size = 1.5, linetype = "solid") +
  geom_sf(data = traffic_data_aggregated %>% filter(!is.na(aadt)),
          aes(color = aadt), 
          size = 0.2) +
  scale_color_viridis_c(
    name = "AADT",
    option = "plasma",
    labels = scales::comma) +
  theme_bw() +
  labs(title = "Annual Average Daily Traffic") 
print(traffic_roads)
```


As follows we normalize the accidents by the traffic volume. To do so, we first assign each accident to its nearest post miles point and calculate the distance between these two. Secondly, we aggregate the accident data by closest traffic point and calculate the normalized accident rates. For each traffic point, we count the number of accidents and then divide these counts by the average AADT and multiply by 1,000 to get the rate per 1,000 vehicles. 

```{r}
# Assign each accident to its nearest traffic measurement point 
normalize_accidents_by_traffic <- function(df.acc.sf, traffic_data_aggregated, buffer_distance = 300) {
  # Match coordinate systems
  traffic_data_aggregated <- st_transform(traffic_data_aggregated, st_crs(df.acc.sf))
  
  # Find the nearest traffic point for each accident
  nearest_indices <- st_nearest_feature(df.acc.sf, traffic_data_aggregated)
  
  # Calculate distances to each nearest point
  distances <- st_distance(df.acc.sf, traffic_data_aggregated[nearest_indices,], by_element = TRUE)
  distances <- as.numeric(distances)
  
  # Add traffic data directly to the accidents dataframe
  df.acc.sf$aadt <- traffic_data_aggregated$aadt[nearest_indices]
  
  # Add the traffic point ID to each accident 
  df.acc.sf$traffic_point_id <- nearest_indices
  
  # Flag accidents that fall within the buffer distance
  df.acc.sf$within_buffer <- distances <= buffer_distance
  
  return(df.acc.sf)}

# Apply the function
df.acc.sf <- normalize_accidents_by_traffic(df.acc.sf, traffic_data_aggregated)

# Count accidents per traffic point and normalize accidents counts
traffic_point_stats <- df.acc.sf %>%
  st_drop_geometry() %>%  
  group_by(traffic_point_id) %>%
  summarise(
    accident_count = n(),
    aadt = first(aadt),  
    accidents_per_1000_vehicles = (accident_count / aadt) * 1000)

# Create a new spatial object with traffic points and their accident rates
traffic_points_with_rates <- traffic_data_aggregated %>%
  mutate(traffic_point_id = row_number()) %>%  
  left_join(traffic_point_stats, by = "traffic_point_id") %>%
  mutate(
    accident_count = replace_na(accident_count, 0),
    accidents_per_1000_vehicles = replace_na(accidents_per_1000_vehicles,0))

```


As expected, the traffic volume does have an impact on accidents, so this normalization step was crucial in order to have robust and reliable results.

```{r}
# Distribution of accidents by traffic volume
ggplot(df.acc.sf %>% filter(!is.na(aadt)), 
       aes(x = aadt)) +
  geom_histogram(bins = 30, fill = "steelblue") +
  scale_x_log10() +  
  theme_minimal() +
  labs(title = "Accidents by Traffic Volume",
       x = "Average Daily Traffic Volume (logarithmic scale)",
       y = "Number of Accidens")
```



For further visualizations, we also calculate buffers to verify the intersection between areas close to construction sites and frequency of accidents.
```{r}
# Create construction buffers 
create_construction_buffers <- function(df.const.sf, buffer_distance = 300) {
  # Ensure proper projection
  df.const.projected <- st_transform(df.const.sf, 3310)  # California Albers projection
  
  # Create buffers
  construction_buffers <- st_buffer(df.const.projected, dist = buffer_distance)
  
  # Transform back to original CRS
  construction_buffers <- st_transform(construction_buffers, st_crs(df.const.sf))
  return(construction_buffers)}

# Apply the function 
construction_buffers <- create_construction_buffers(df.const.sf)
```


Due to memory constraints, the following interactive map has been further filtered to focus solely on Los Angeles. This visualization highlights construction buffers (areas within 300 meters of construction sites) in red, and accidents in blue. We specifically chose Los Angeles for this analysis, as prior visualizations revealed that most accidents and construction sites are concentrated in this region, along with Sacramento. This is to be expected, given the high population density in these areas.

```{r}
# Define the Los Angeles bounding box
la_bbox <- list(
  min_lng = -118.75, max_lng = -117.85,
  min_lat = 33.65, max_lat = 34.35)

# Filter data for Los Angeles
la_accidents <- df.acc.sf %>%
  filter(
    st_coordinates(.)[,1] >= la_bbox$min_lng,
    st_coordinates(.)[,1] <= la_bbox$max_lng,
    st_coordinates(.)[,2] >= la_bbox$min_lat,
    st_coordinates(.)[,2] <= la_bbox$max_lat)

la_buffers <- construction_buffers %>%
  st_filter(st_as_sfc(st_bbox(c(
    xmin = la_bbox$min_lng, xmax = la_bbox$max_lng,
    ymin = la_bbox$min_lat, ymax = la_bbox$max_lat
  ), crs = st_crs(construction_buffers))))

# Interactive map for accidents within construction buffers 
la_buffer_accident_map <- leaflet() %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  # Add construction buffers
  addPolygons(data = la_buffers, 
              color = "#FF5500", 
              weight = 2, 
              opacity = 0.8,
              fillOpacity = 0.4,
              group = "Construction Buffers") %>%
  # Add accidents 
  addCircles(data = la_accidents,
             radius = 1.5,  
             color = "#3388FF",
             fillColor = "#3388FF",
             fillOpacity = 0.6,
             weight = 1,
             group = "Accidents") %>%
  # Add layer controls
  addLayersControl(
    overlayGroups = c("Construction Buffers", "Accidents"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>%
  # Center on Los Angeles
  setView(lng = -118.25, lat = 34.05, zoom = 10)
la_buffer_accident_map

```



<hr>



## 3.2 Propensity Score Matching

## 3.3 Difference-in-Differences

# Part 4 - Discussion

## 4.1 Results

## 4.2 Limitations

## 4.3 Improvements